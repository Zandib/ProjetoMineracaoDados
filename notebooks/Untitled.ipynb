{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training files...\n",
      "Extract training features...\n",
      "class a extracted\n",
      "class b extracted\n",
      "class c extracted\n",
      "class d extracted\n",
      "class h extracted\n",
      "class m extracted\n",
      "class n extracted\n",
      "class x extracted\n",
      "class 6 extracted\n",
      "class 7 extracted\n",
      "Creating validation files...\n",
      "Extracting validation features\n",
      "class a extracted\n",
      "class b extracted\n",
      "class c extracted\n",
      "class d extracted\n",
      "class h extracted\n",
      "class m extracted\n",
      "class n extracted\n",
      "class x extracted\n",
      "class 6 extracted\n",
      "class 7 extracted\n",
      "Training set saved at data.csv\n",
      "Validation set save at data_validacao.csv\n",
      "Accuracy of linear SVM: 0.653558052434457\n",
      "Tuning RBF Kernel parameters\n",
      "Search grid for RBF returned parameters:\n",
      "{'C': 3.0, 'gamma': 0.1}\n",
      "Params:\n",
      "{'C': 3.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "Accuracy score of RBF Kernel: 0.7303370786516854\n",
      "Re-training with validation data\n",
      "Training + Validation score(cross-val) 0.7271342834934078\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: dib_n\n",
    "\"\"\"\n",
    "#################################################################\n",
    "#Imports\n",
    "#################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Learning\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#SearchGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Resample\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#Saving \n",
    "from sklearn.externals import joblib \n",
    "\n",
    "#################################################################\n",
    "#Prep train/validation set from external file\n",
    "#################################################################\n",
    "exec(open('../scripts/dataprep_treino_validacao.py').read())\n",
    "#################################################################\n",
    "#Loads\n",
    "#################################################################\n",
    "#Importando base de treino\n",
    "df_train = pd.read_csv('../data/data.csv',index_col=False)\n",
    "df_valid = pd.read_csv('../data/data_validacao.csv',index_col=False)\n",
    "# Dropping unneccesary columns\n",
    "df_train = df_train.drop(['filename'],axis=1)\n",
    "df_valid = df_valid.drop('filename',axis=1)\n",
    "#################################################################\n",
    "#Encoding\n",
    "#################################################################\n",
    "class_list = df_train.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(class_list)\n",
    "y_train = encoder.transform(class_list)\n",
    "y_valid = encoder.transform(df_valid.iloc[:,-1])\n",
    "joblib.dump(encoder,'../models/encoder.pkl')\n",
    "#################################################################\n",
    "#Scailing\n",
    "#################################################################\n",
    "scaler = StandardScaler()\n",
    "df = df_train.append(df_valid,ignore_index=True)\n",
    "scaler.fit(np.array(df.iloc[:, :-1], dtype = float))\n",
    "X_train = scaler.transform(np.array(df_train.iloc[:, :-1], dtype = float))\n",
    "X_valid = scaler.transform(np.array(df_valid.iloc[:, :-1], dtype = float))\n",
    "joblib.dump(scaler,'../models/scaler.pkl')\n",
    "#################################################################\n",
    "#Training svm with two different kernels\n",
    "#################################################################\n",
    "#Linear\n",
    "SVClassifier = svm.SVC(kernel='linear')\n",
    "SVClassifier.fit(X_train,y_train)\n",
    "print('Accuracy of linear SVM:',SVClassifier.score(X_valid,y_valid))\n",
    "joblib.dump(SVClassifier,'../models/svclinear.pkl')\n",
    "#Rbf\n",
    "##################################################################\n",
    "#Param grid\n",
    "Cs = np.arange(0.5,100,0.5)\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "param_grid = {'C':Cs,'gamma':gammas}\n",
    "#################################################################\n",
    "#Grid Search\n",
    "print('Tuning RBF Kernel parameters')\n",
    "grid_search = GridSearchCV(svm.SVC(kernel='rbf'),param_grid)\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('Search grid for RBF returned parameters:')\n",
    "print(grid_search.best_params_)\n",
    "#Get model  \n",
    "SVCrbf = grid_search.best_estimator_\n",
    "print('Params:')\n",
    "print(SVCrbf.get_params())\n",
    "#SVCrbf.fit(X_train,y_train)\n",
    "print('Accuracy score of RBF Kernel:',SVCrbf.score(X_valid,y_valid))\n",
    "joblib.dump(SVCrbf, '../models/svcrbf.pkl') \n",
    "##################################################################\n",
    "#Re-treino com validação\n",
    "##################################################################\n",
    "print('Re-training with validation data')\n",
    "X = np.concatenate((X_train,X_valid))\n",
    "y = np.concatenate((y_train,y_valid))\n",
    "\n",
    "SVCrbf = joblib.load('../models/svcrbf.pkl')\n",
    "SVCrbf.fit(X,y)\n",
    "#Scoring\n",
    "scores = cross_val_score(SVCrbf, X, y, cv = 3)\n",
    "print('Training + Validation score(cross-val)',scores.mean())\n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "##################################################################\n",
    "#Paradigma One vs All\n",
    "##################################\n",
    "print('Implementing OneVsAll')\n",
    "#Separando uma coluna para cada target\n",
    "for target in df['label'].unique():\n",
    "    df[target] = (df['label']==target).astype(int)\n",
    "    df_train[target] = (df_train['label']==target).astype(int)\n",
    "    df_valid[target] = (df_valid['label']==target).astype(int)\n",
    "#Treinando um modelo para cada classe\n",
    "models={}\n",
    "    \n",
    "models['geral'] = joblib.load('../models/SVCrbf.pkl')\n",
    "\n",
    "backup_X_train = X_train.copy()\n",
    "backup_y_train = y_train.copy()\n",
    "backup_X_valid = X_valid.copy()\n",
    "backup_y_valid = y_valid.copy()\n",
    "\n",
    "for target in df['label'].unique():\n",
    "    \n",
    "    X_train = backup_X_train.copy()\n",
    "    y_train = backup_y_train.copy()\n",
    "    X_valid = backup_X_valid.copy()\n",
    "    y_valid = backup_y_valid.copy()\n",
    "    \n",
    "    train_temp = pd.DataFrame(X_train)\n",
    "    train_temp[str(target)]=df_train[target].copy()\n",
    "    \n",
    "    train_temp_nao_target = train_temp.loc[train_temp[target]==0]\n",
    "    train_temp_target = train_temp.loc[train_temp[target]==1]\n",
    "    \n",
    "    train_temp_upsampled = resample(train_temp_target,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(train_temp_nao_target)/2), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "    \n",
    "    # combine majority and upsampled minority\n",
    "    train_temp = pd.concat([train_temp_nao_target, train_temp_upsampled])\n",
    "    \n",
    "    X_train = train_temp.iloc[:,:-1]\n",
    "    y_train = train_temp.iloc[:,-1]\n",
    "    \n",
    "    #del SVCrbf\n",
    "    SVCrbf = svm.SVC(\n",
    "        kernel='rbf',\n",
    "        gamma=0.1,\n",
    "        C=3\n",
    "    )\n",
    "    #print(X_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    \n",
    "    SVCrbf.fit(X_train,y_train)\n",
    "    print(\"**********************************************************************\")\n",
    "    print(\"Acuracia para a classe \"+target+\":\",SVCrbf.score(X_valid,df_valid[target]))\n",
    "    predictions = SVCrbf.predict(X_valid)\n",
    "    print(\"Roc AUC score para a classe \"+target+\":\",roc_auc_score(df_valid[target],predictions))\n",
    "    print(\"Precision:\",precision_score(df_valid[target],predictions))\n",
    "    print(\"Recall:\",recall_score(df_valid[target],predictions))\n",
    "    \n",
    "    #For re-training, oversample will also be used\n",
    "    train_temp = pd.DataFrame(X_valid)\n",
    "    train_temp[str(target)]=df_valid[target].copy()\n",
    "    \n",
    "    train_temp_nao_target = train_temp.loc[train_temp[target]==0]\n",
    "    train_temp_target = train_temp.loc[train_temp[target]==1]\n",
    "    \n",
    "    train_temp_upsampled = resample(train_temp_target,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(train_temp_nao_target)/2), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "    \n",
    "    # combine majority and upsampled minority\n",
    "    train_temp = pd.concat([train_temp_nao_target, train_temp_upsampled])\n",
    "    \n",
    "    X_valid2 = train_temp.iloc[:,:-1]\n",
    "    y_valid2 = train_temp.iloc[:,-1]\n",
    "    \n",
    "    X = np.concatenate((X_train,X_valid2))\n",
    "    y = np.concatenate((y_train,y_valid2))\n",
    "    SVCrbf.fit(X,y)\n",
    "    #Scoring\n",
    "    scores = cross_val_score(SVCrbf, X, y, cv = 3)\n",
    "    print('Training + Validation score(cross-val) para classe '+target+':',scores.mean())\n",
    "    joblib.dump(SVCrbf,'../models/SVCrbf_'+target+'.pkl')\n",
    "    models[target]=joblib.load('../models/SVCrbf_'+target+'.pkl')\n",
    "    \n",
    "print(\"**********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
